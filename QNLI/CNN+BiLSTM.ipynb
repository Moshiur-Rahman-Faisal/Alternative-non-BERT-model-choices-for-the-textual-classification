{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-6hmel6sKNSP"
   },
   "outputs": [],
   "source": [
    "def reproduceResult():\n",
    "  seed_value= 0\n",
    "\n",
    "  \n",
    "  with tf.device(\"/cpu:0\"):\n",
    "    ...\n",
    "\n",
    "\n",
    "  os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "  np.random.seed(0)\n",
    "  rn.seed(0)\n",
    "\n",
    "\n",
    "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, \n",
    "                                          inter_op_parallelism_threads=1)\n",
    "\n",
    "\n",
    "  tf.compat.v1.set_random_seed(seed_value)\n",
    "  sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "  tf.compat.v1.keras.backend.set_session(sess)\n",
    "  tf.compat.v1.keras.backend.clear_session()\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vURLkAC5_Jp0",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\moshi\\AppData\\Local\\Temp/ipykernel_13036/4179402048.py:20: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moshi\\AppData\\Local\\Temp/ipykernel_13036/628588012.py:43: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "  \n",
    "import os \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from tensorflow import keras\n",
    "\n",
    "reproduceResult()\n",
    "# %tensorflow_version 2.x\n",
    "# import tensorflow as tf\n",
    "# tf.test.gpu_device_name()\n",
    "# from scipy import integrate\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from tensorflow import keras\n",
    "import tempfile\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "# import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "from keras_lr_finder import LRFinder\n",
    "from clr.clr_callback import CyclicLR\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "\n",
    "\n",
    "import keras_tuner\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from attention import Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moshi\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\moshi\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('qnli1.csv',index_col=False, encoding='iso-8859-1', \n",
    "                                warn_bad_lines=True, error_bad_lines=False)\n",
    "\n",
    "df2 = pd.read_csv('qnli1.csv',index_col=False, encoding='iso-8859-1', \n",
    "                                warn_bad_lines=True, error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.dropna of                                                question  \\\n",
       "0              When did the third Digimon series begin?   \n",
       "1     Which missile batteries often have individual ...   \n",
       "2     What two things does Popper argue Tarski's the...   \n",
       "3     What is the name of the village 9 miles north ...   \n",
       "4              What famous palace is located in London?   \n",
       "...                                                 ...   \n",
       "1427  The first American to travel into space was whom?   \n",
       "1428  How many years does a president have in office...   \n",
       "1429     What is the second principle of Protestantism?   \n",
       "1430  WHat is the earliest surviving use of the clan...   \n",
       "1431                                What are morphemes?   \n",
       "\n",
       "                                               sentence           label  \n",
       "0     Unlike the two seasons before it and most of t...  not_entailment  \n",
       "1     When MANPADS is operated by specialists, batte...  not_entailment  \n",
       "2     He bases this interpretation on the fact that ...      entailment  \n",
       "3     On 31 December 1853, the Ottoman forces at Cal...      entailment  \n",
       "4     London contains four World Heritage Sites: the...  not_entailment  \n",
       "...                                                 ...             ...  \n",
       "1427  Though he did not achieve orbit like Gagarin, ...  not_entailment  \n",
       "1428  The island has a president (elected every five...      entailment  \n",
       "1429  The second main principle, sola fide (by faith...      entailment  \n",
       "1430  The documentation regarding Raciborz and Alber...      entailment  \n",
       "1431  It is an agglutinative language; in other word...      entailment  \n",
       "\n",
       "[1432 rows x 3 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dropna\n",
    "df2.dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entailment        759\n",
       "not_entailment    673\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entailment        759\n",
       "not_entailment    673\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking acceptable and deleting unacceptable\n",
    "df3 = df1[df1['label'] == 'entailment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                question  \\\n",
       "2     What two things does Popper argue Tarski's the...   \n",
       "3     What is the name of the village 9 miles north ...   \n",
       "5     When is the term 'German dialects' used in reg...   \n",
       "6     What was the name of the island the English tr...   \n",
       "8      What does the word 'customer' properly apply to?   \n",
       "...                                                 ...   \n",
       "1422     Where was the band Talking Heads based out of?   \n",
       "1428  How many years does a president have in office...   \n",
       "1429     What is the second principle of Protestantism?   \n",
       "1430  WHat is the earliest surviving use of the clan...   \n",
       "1431                                What are morphemes?   \n",
       "\n",
       "                                               sentence       label  \n",
       "2     He bases this interpretation on the fact that ...  entailment  \n",
       "3     On 31 December 1853, the Ottoman forces at Cal...  entailment  \n",
       "5     When talking about the German language, the te...  entailment  \n",
       "6     At the end of the Second Anglo-Dutch War, the ...  entailment  \n",
       "8     The bill also required rotation of principal m...  entailment  \n",
       "...                                                 ...         ...  \n",
       "1422  A variety of subsequent groups, including New ...  entailment  \n",
       "1428  The island has a president (elected every five...  entailment  \n",
       "1429  The second main principle, sola fide (by faith...  entailment  \n",
       "1430  The documentation regarding Raciborz and Alber...  entailment  \n",
       "1431  It is an agglutinative language; in other word...  entailment  \n",
       "\n",
       "[759 rows x 3 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# randomly picking 250 rows\n",
    "df3 = df3.sample(n=250, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entailment    250\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking unacceptable and deleting unacceptable\n",
    "df4 = df2[df2['label'] == 'not_entailment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly picking 250 rows\n",
    "df4 = df4.sample(n=250, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_entailment    250\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concating acceptable and unacceptable\n",
    "frames = [df3, df4]\n",
    "\n",
    "temp = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entailment        250\n",
       "not_entailment    250\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFgD7Seo_Xlq",
    "outputId": "9be2fe5a-b7b5-4488-9cd4-8a48ce6123e8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 4183\n",
      "[[ 267  268 1984 ...    1 2002  461]\n",
      " [   0    0    0 ...  673  463  674]\n",
      " [  15 1008 1009 ...    3 1028 1029]\n",
      " ...\n",
      " [   0    0    0 ...    4  999  349]\n",
      " [   0    0    0 ...    1  352 1977]\n",
      " [   0    0    0 ... 1000 1675 4183]]\n",
      "(4184, 300)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(temp, test_size=0.2, stratify = temp['label'], random_state = 42)\n",
    "num_classes = 2\n",
    "embed_num_dims = 300\n",
    "max_seq_len = 50\n",
    "\n",
    "x_train = train['question'] + train['sentence']\n",
    "x_test = test['question'] + test['sentence']\n",
    "\n",
    "y_train = train['label']\n",
    "y_test = test['label']\n",
    "\n",
    "texts_train = x_train\n",
    "texts_test = x_test\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train['question'] + train['sentence'])\n",
    "\n",
    "sequence_train = tokenizer.texts_to_sequences(texts_train)\n",
    "sequence_test = tokenizer.texts_to_sequences(texts_test)\n",
    "\n",
    "index_of_words = tokenizer.word_index\n",
    "\n",
    "vocab_size = len(index_of_words) + 1\n",
    "\n",
    "print('Number of unique words: {}'.format(len(index_of_words)))\n",
    "\n",
    "X_train_pad = pad_sequences(sequence_train, maxlen = max_seq_len, padding='pre' )\n",
    "X_test_pad = pad_sequences(sequence_test, maxlen = max_seq_len,  padding='pre')\n",
    "\n",
    "print(X_train_pad)\n",
    "\n",
    "\n",
    "encoding = {\n",
    "    'entailment': 1,\n",
    "    'not_entailment': 0\n",
    "}\n",
    "\n",
    "y_train = [encoding[x] for x in train['label']]\n",
    "y_test = [encoding[x] for x in test['label']]\n",
    "\n",
    "\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "def create_embedding_matrix(word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    with open('C:/Users/moshi/Python Code/Untitled Folder/cc.en.300.vec',encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "embedd_matrix = create_embedding_matrix(index_of_words, embed_num_dims)\n",
    "print(embedd_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGgsd5mMZPKn"
   },
   "source": [
    "# Random Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import  convert_variables_to_constants_v2_as_graph\n",
    "\n",
    "def get_flops(model):\n",
    "    concrete = tf.function(lambda inputs: model(inputs))\n",
    "    concrete_func = concrete.get_concrete_function(\n",
    "        [tf.TensorSpec([1, *inputs.shape[1:]]) for inputs in model.inputs])\n",
    "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(concrete_func)\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.graph_util.import_graph_def(graph_def, name='')\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n",
    "        return flops.total_float_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3IvOZoK8YGDI",
    "outputId": "fe861031-a89e-45d3-8f7a-42f1e7b6b256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 Complete [00h 00m 46s]\n",
      "val_accuracy: 0.6800000071525574\n",
      "\n",
      "Best val_accuracy So Far: 0.7099999785423279\n",
      "Total elapsed time: 00h 40m 28s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in 1653506366\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 32\n",
      "cnn_1_unit: 48\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 160\n",
      "lstm_dropout: 0.30000000000000004\n",
      "Score: 0.7099999785423279\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 64\n",
      "cnn_1_unit: 64\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 128\n",
      "lstm_dropout: 0.1\n",
      "Score: 0.7099999785423279\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 112\n",
      "cnn_1_unit: 48\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 64\n",
      "lstm_dropout: 0.1\n",
      "Score: 0.699999988079071\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 80\n",
      "cnn_1_unit: 96\n",
      "cnn_1_dropout: 0.1\n",
      "lstm_unit: 160\n",
      "lstm_dropout: 0.2\n",
      "Score: 0.699999988079071\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 64\n",
      "cnn_1_unit: 96\n",
      "cnn_1_dropout: 0.30000000000000004\n",
      "lstm_unit: 96\n",
      "lstm_dropout: 0.5\n",
      "Score: 0.699999988079071\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 64\n",
      "cnn_1_unit: 48\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 128\n",
      "lstm_dropout: 0.30000000000000004\n",
      "Score: 0.699999988079071\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 64\n",
      "cnn_1_unit: 48\n",
      "cnn_1_dropout: 0.30000000000000004\n",
      "lstm_unit: 128\n",
      "lstm_dropout: 0.4\n",
      "Score: 0.6899999976158142\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 80\n",
      "cnn_1_unit: 64\n",
      "cnn_1_dropout: 0.30000000000000004\n",
      "lstm_unit: 128\n",
      "lstm_dropout: 0.30000000000000004\n",
      "Score: 0.6899999976158142\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 64\n",
      "cnn_1_unit: 80\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 64\n",
      "lstm_dropout: 0.30000000000000004\n",
      "Score: 0.6899999976158142\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "attention_unit: 48\n",
      "cnn_1_unit: 96\n",
      "cnn_1_dropout: 0.1\n",
      "lstm_unit: 224\n",
      "lstm_dropout: 0.2\n",
      "Score: 0.6899999976158142\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "import time\n",
    "LOG_DIR = f\"{int(time.time())}\"\n",
    "seed_value= 0\n",
    "\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "  \n",
    "  reproduceResult()\n",
    "\n",
    "  print('Ya it comes here')\n",
    "  unit_attention = hp.Int(\"attention_unit\",min_value =32, max_value = 128, step = 16)\n",
    "  fake_val = hp.Int(\"cnn_1_unit\",min_value =16, max_value = 96, step = 16)\n",
    "  cnn_1_unit = hp.Int(\"cnn_1_unit\",min_value =16, max_value = 96, step = 16)\n",
    "  cnn_1_dropout = hp.Float(\"cnn_1_dropout\",min_value = 0.1,max_value = 0.3,step = 0.1)\n",
    "\n",
    "  lstm_unit = hp.Int(\"lstm_unit\",min_value =64, max_value = 256, step = 32)\n",
    "  lstm_dropout = hp.Float(\"lstm_dropout\",min_value = 0.1,max_value = 0.5,step = 0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  seq_input = keras.layers.Input(shape=(max_seq_len,))\n",
    "\n",
    "  embedded = keras.layers.Embedding(vocab_size,\n",
    "                          embed_num_dims,\n",
    "                          input_length = max_seq_len,\n",
    "                          weights = [embedd_matrix])(seq_input)\n",
    "\n",
    "  cnn = keras.layers.Conv1D(cnn_1_unit,3,kernel_regularizer=regularizers.l2(1e-4),\n",
    "                            bias_regularizer=regularizers.l2(1e-2),\n",
    "                            activity_regularizer=regularizers.l2(1e-4))(embedded)\n",
    "  cnn = keras.layers.Activation(activation='relu')(cnn)\n",
    "  cnn = keras.layers.BatchNormalization()(cnn)\n",
    "  cnn = keras.layers.Dropout(cnn_1_dropout,seed=seed_value)(cnn)\n",
    "\n",
    "\n",
    "  lstm = keras.layers.Bidirectional(keras.layers.LSTM(lstm_unit, recurrent_regularizer=regularizers.l2(1e-4),\n",
    "                                                      return_sequences=True,kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                                      bias_regularizer=regularizers.l2(1e-2),\n",
    "                                                      activity_regularizer=regularizers.l2(1e-4),input_shape =(48,)))(cnn)\n",
    "  lstm = keras.layers.Activation(activation='relu')(lstm)\n",
    "  lstm = keras.layers.BatchNormalization()(lstm)\n",
    "  lstm = keras.layers.Dropout(lstm_dropout,seed=seed_value)(lstm)\n",
    "  \n",
    "  \n",
    "\n",
    "  max_pooling = keras.layers.GlobalMaxPooling1D()(lstm)\n",
    "  output = keras.layers.Dense(num_classes, activation='softmax')(max_pooling)\n",
    "\n",
    "  model = keras.Model(inputs = [seq_input], outputs = output)\n",
    "  model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "  model.summary()\n",
    "  \n",
    "  print(\"The FLOPs is:{}\".format(get_flops(model)) ,flush=True )\n",
    "    \n",
    "  print(\" \")\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "clr_step_size = int((len(X_train_pad)/64))\n",
    "base_lr = 1e-3\n",
    "max_lr = 6e-3\n",
    "mode = 'exp_range'\n",
    "\n",
    "\n",
    "clr = CyclicLR(base_lr = base_lr, max_lr = max_lr, step_size = clr_step_size, mode = mode)\n",
    "\n",
    "stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                              patience=5,\n",
    "                              restore_best_weights=True,\n",
    "                              verbose=0, mode='max')\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = keras_tuner.Objective('val_accuracy', direction=\"max\"),\n",
    "    max_trials = 40,\n",
    "    executions_per_trial = 1,\n",
    "    directory = LOG_DIR\n",
    "    )\n",
    "  \n",
    "tuner.search(x=X_train_pad,y = y_train,epochs = 25, batch_size = 4,callbacks = [stop,clr], \n",
    "             validation_data = (X_test_pad,y_test))\n",
    "\n",
    "\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "attention_unit (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': None}\n",
      "cnn_1_unit (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 96, 'step': 16, 'sampling': None}\n",
      "cnn_1_dropout (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.3, 'step': 0.1, 'sampling': None}\n",
      "lstm_unit (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 256, 'step': 32, 'sampling': None}\n",
      "lstm_dropout (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "model = build_model(best_hps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 6s 39ms/step - loss: 0.3800 - accuracy: 0.9725 - val_loss: 1.3054 - val_accuracy: 0.6100\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.5650 - accuracy: 0.9350 - val_loss: 2.3699 - val_accuracy: 0.6400\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.4212 - accuracy: 0.9775 - val_loss: 1.4113 - val_accuracy: 0.6300\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.3937 - accuracy: 0.9750 - val_loss: 1.4218 - val_accuracy: 0.6000\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.3614 - accuracy: 0.9800 - val_loss: 1.3465 - val_accuracy: 0.6600\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.3353 - accuracy: 0.9775 - val_loss: 1.4741 - val_accuracy: 0.6300\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.3559 - accuracy: 0.9725 - val_loss: 1.9773 - val_accuracy: 0.6200\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.3530 - accuracy: 0.9700 - val_loss: 1.4138 - val_accuracy: 0.6200\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.3355 - accuracy: 0.9775 - val_loss: 2.1781 - val_accuracy: 0.6300\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.4034 - accuracy: 0.9725 - val_loss: 1.9433 - val_accuracy: 0.6400\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(x=X_train_pad,y = y_train,epochs = 20, batch_size = 4,callbacks = [stop,clr], \n",
    "             validation_data = (X_test_pad,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9850\n",
      "Testing Accuracy:  0.7100\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train_pad, y_train, verbose=0)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "100_percent_test_BiLSTM_best_model_git.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
